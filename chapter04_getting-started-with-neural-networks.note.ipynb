{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 옮긴이 노트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 클래스 벡터(정수)를 이진 클래스 행렬로 변환\n",
    "- 예를 들어, `categorical_crossentropy`와 같이 사용하기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "```python\n",
    "keras.utils.to_categorical(y, num_classes=None, dtype='float32')\n",
    "\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "    - `y`: 행렬로 변환될 클래스 값 갖는 배열 (0에서 `num_classes - 1`까지의 정수)\n",
    "    - `num_classes`: 클래스의 총 개수. `None`이면, 이것은 `max(y) + 1`로 추론.\n",
    "    - `dtype`: 입력에서 예상하는 데이터 유형. 기본값: `'float32'`.\n",
    "\n",
    "- 반환\n",
    "    - 입력의 이진 행렬 표현. 클래스 축은 마지막에 위치."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.utils.to_categorical\")\n",
    "def to_categorical(y, num_classes=None, dtype=\"float32\"):\n",
    "    y = np.array(y, dtype=\"int\")\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "a = to_categorical([0, 1, 2, 3], num_classes=4)\n",
    "a = tf.constant(a, shape=[4, 4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import categorical_crossentropy\n",
    "import numpy as np\n",
    "\n",
    "b = tf.constant([.9, .04, .03, .03,\n",
    "                 .3, .45, .15, .13,\n",
    "                 .04, .01, .94, .05,\n",
    "                 .12, .21, .5, .17],\n",
    "                 shape=[4, 4])\n",
    "loss = categorical_crossentropy(a, b)\n",
    "print(np.around(loss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = categorical_crossentropy(a, a)\n",
    "print(np.around(loss, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 로짓을 가진 시그모이드 교차 엔트로피\n",
    "- 주어진 `logits`으로 시그모이드 교차 엔트로피 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "    \n",
    "```python\n",
    "tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    name=None,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "    - `labels`: `logits`과 동일한 유형 및 형태. 배타적으로 0에서 1 사이.\n",
    "    - `logits`: `float32` 또는 `float64` 유형의 텐서. 모든 실수.\n",
    "    - `name`: 연산에 대한 이름 (선택사양).\n",
    "\n",
    "- 반환:\n",
    "    - 구성 요소별 로지스틱 손실이 있는 'logits'과 동일한 형태의 'Tensor'.\n",
    "\n",
    "- 발생:\n",
    "    - `ValueError`: `logits` 및 `labels`이 동일한 형태를 가지고 있지 않으면."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**설명:**\n",
    "\n",
    "각 결과가 독립적이고 완전하게 특정 레이블을 가질 필요가 없는 두 결과가 있는 작업에서 확률 오차를 측정한다.\n",
    "예를 들어, 사건 발생 확률을 알고 레이블로 사용하는 회귀를 수행할 수 있다. 이 손실은 이진 분류에도 사용될 수 있다.\n",
    "이 손실은 레이블이 0 또는 1인 이진 분류에도 사용될 수 있다.\n",
    "\n",
    "  \n",
    "\n",
    "간략하게, `x = logits`, `z = labels` 하자. 로지스틱 손실은\n",
    "\n",
    "        z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n",
    "      = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n",
    "      = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n",
    "      = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n",
    "      = (1 - z) * x + log(1 + exp(-x))\n",
    "      = x - x * z + log(1 + exp(-x))\n",
    "\n",
    "x < 0 대하여, exp(-x)에서 과다를 방지하기 위해 위의 공식을 재구성한다:\n",
    "\n",
    "        x - x * z + log(1 + exp(-x))\n",
    "      = log(exp(x)) - x * z + log(1 + exp(-x))\n",
    "      = - x * z + log(1 + exp(x))\n",
    "\n",
    "따라서, 안정성을 보장하고 오버플로를 방지하기 위해, 구현은 이와 동등한 공식을 사용한다.\n",
    "\n",
    "      max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
    "\n",
    "`logits` 및 `labels` 반드시 동일 유형과 형태를 가져야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.constant([1., -1., 0., 1., -1., 0., 0.])\n",
    "labels = tf.constant([0., 0., 0., 1., 1., 1., 0.5])\n",
    "tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 결과를 처리하는 손실과 비교하여, 일반적인 다중 클래스 분류를 위한 `tf.nn.softmax_cross_entropy_with_logits` 및 하드 레이블이 있는 보다 효율적인 다중 클래스 분류를 위한 `tf.nn.sparse_softmax_cross_entropy_with_logits`는 이진 분류를 약간 단순화한 것이다:\n",
    "\n",
    "        sigmoid(x) = softmax([x, 0])[0]\n",
    "\n",
    "  $$\\frac{1}{1 + e^{-x}} = \\frac{e^x}{e^x + e^0}$$\n",
    "\n",
    "`sigmoid_cross_entropy_with_logits`는 (0과 1 사이의 확률) 소프트 이진 레이블에 대해 작동하지만, 레이블이 어려운 이진 분류에도 사용할 수 있다.\n",
    "모든 세 기호 사이에 동일한 경우에, 확률 0은 두 번째 클래스를 가리키거나 또는 1은 첫 번째 클래스를 가리킨다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_logits = tf.constant([1., -1., 0.])\n",
    "softmax_logits = tf.stack([sigmoid_logits, tf.zeros_like(sigmoid_logits)], axis=-1)\n",
    "soft_binary_labels = tf.constant([1., 1., 0.])\n",
    "soft_multiclass_labels = tf.stack([soft_binary_labels, 1. - soft_binary_labels], axis=-1)\n",
    "hard_labels = tf.constant([0, 0, 1])\n",
    "tf.nn.sparse_softmax_cross_entropy_with_logits(labels=hard_labels, logits=softmax_logits).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits(labels=soft_multiclass_labels, logits=softmax_logits).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.sigmoid_cross_entropy_with_logits(labels=soft_binary_labels, logits=sigmoid_logits).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "    \n",
    "```python\n",
    "@tf_export(\"nn.sigmoid_cross_entropy_with_logits\", v1=[])\n",
    "@dispatch.register_binary_elementwise_api\n",
    "@dispatch.add_dispatch_support\n",
    "def sigmoid_cross_entropy_with_logits_v2(  # pylint: disable=invalid-name\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    name=None):\n",
    "  return sigmoid_cross_entropy_with_logits(\n",
    "      logits=logits, labels=labels, name=name)\n",
    "\n",
    "\n",
    "@tf_export(v1=[\"nn.sigmoid_cross_entropy_with_logits\"])\n",
    "@dispatch.add_dispatch_support\n",
    "def sigmoid_cross_entropy_with_logits(  # pylint: disable=invalid-name\n",
    "    _sentinel=None,\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    name=None):\n",
    "  \"\"\"sigmoid_cross_entropy_with_logits_v2 참조.\"\"\"\n",
    "  # pylint: disable=protected-access\n",
    "  nn_ops._ensure_xent_args(\"sigmoid_cross_entropy_with_logits\", _sentinel,\n",
    "                           labels, logits)\n",
    "  # pylint: enable=protected-access\n",
    "\n",
    "  with ops.name_scope(name, \"logistic_loss\", [logits, labels]) as name:\n",
    "    logits = ops.convert_to_tensor(logits, name=\"logits\")\n",
    "    labels = ops.convert_to_tensor(labels, name=\"labels\")\n",
    "    try:\n",
    "      labels.get_shape().assert_is_compatible_with(logits.get_shape())\n",
    "    except ValueError:\n",
    "      raise ValueError(\"`logits` and `labels` must have the same shape, \"\n",
    "                       f\"received ({logits.get_shape()} vs \"\n",
    "                       f\"{labels.get_shape()}).\")\n",
    "\n",
    "    # 위의 로지스틱 손실 공식\n",
    "    #   x - x * z + log(1 + exp(-x))\n",
    "    # x < 0 대하여, 좀 더 수치적으로 안정된 공식은\n",
    "    #   -x * z + log(1 + exp(x))\n",
    "    # 이들 두 표현식은 다음과 같이 결합될 수 있다:\n",
    "    #   max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
    "    # 0에서 경사를 계산할 수 있도록 max 및 abs 함수의 사용자 지정 버전을 정의.\n",
    "    zeros = array_ops.zeros_like(logits, dtype=logits.dtype)\n",
    "    cond = (logits >= zeros)\n",
    "    relu_logits = array_ops.where(cond, logits, zeros)\n",
    "    neg_abs_logits = array_ops.where(cond, -logits, logits)  # pylint: disable=invalid-unary-operand-type\n",
    "    return math_ops.add(\n",
    "        relu_logits - logits * labels,\n",
    "        math_ops.log1p(math_ops.exp(neg_abs_logits)),\n",
    "        name=name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 범주형 교차 엔트로피 (backend)\n",
    "- 출력 텐서와 목표 텐서 사이의 범주형 교차 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "keras.backend.categorical_crossentropy(\n",
    "    target,\n",
    "    output,\n",
    "    from_logits=False,\n",
    "    axis=-1,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "    - `target`: `output`와 동일 형태의 텐서\n",
    "    - `output`: 소프트맥스의 텐서 결과 (`from_logits`가 참이 아니면, 이 경우 `output`은 로짓이 될 것으로 예상)\n",
    "    - `from_logits`: 참/거짓, `output`이 소프트맥스의 결과 또는 로짓의 텐서인지 여부\n",
    "    - `axis`: 채널 축을 지정하는 정수. `axis=-1`은 데이터 포맷 `channels_last`이고, `axis=1`은 `channels_first`에 상응\n",
    "- 반환:\n",
    "    - 출력 텐서\n",
    "- 발생:\n",
    "    - `ValueError`: `axis`가 -1도 아니고 `output`의 축 중 하나도 아닌 경우."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.backend.categorical_crossentropy\")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n",
    "    target = tf.convert_to_tensor(target)\n",
    "    output = tf.convert_to_tensor(output)\n",
    "    target.shape.assert_is_compatible_with(output.shape)\n",
    "\n",
    "    output, from_logits = _get_logits(\n",
    "        output, from_logits, \"Softmax\", \"categorical_crossentropy\"\n",
    "    )\n",
    "    if from_logits:\n",
    "        return tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=target, logits=output, axis=axis\n",
    "        )\n",
    "\n",
    "    # 각 샘플의 확률 클래스 합계가 1이 되도록 예측를 조정\n",
    "    output = output / tf.reduce_sum(output, axis, True)\n",
    "    # 확률로 부터 교차 엔트로피 계산\n",
    "    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n",
    "    return -tf.reduce_sum(target * tf.math.log(output), axis)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1., 0., 0., 0., 1., 0., 0., 0., 1.], shape=[3,3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.constant([.9, .05, .05, .05, .89, .06, .05, .01, .94], shape=[3, 3])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import categorical_crossentropy\n",
    "\n",
    "loss = categorical_crossentropy(a, b)\n",
    "print(np.around(loss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = categorical_crossentropy(a, a)\n",
    "print(np.around(loss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.metrics.categorical_crossentropy??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 범주형 교차 엔트로피 (metrics & losses)\n",
    "- 범주형 교차 엔트로피 손실 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 `tf.keras.[metrics|losess].categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "categorical_crossentropy(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - y_true: 원-핫 참 목표의 텐서.\n",
    "  - y_pred: 예측된 목표의 텐서.\n",
    "  - from_logits: `y_pred`가 로짓 텐서인지 여부. 기본적으로 `y_pred`가 확률 분포를 인코딍한다고 가정.\n",
    "  - label_smoothing: [0, 1] 범위의 부동소수점. `0`보다 크면 레이블을 부드럽게 한다. \n",
    "    예를 들어, `0.1`인 경우 비대상 레이블에 `0.1 / num_classes`를 사용하고 대상 레이블에 `0.9 + 0.1 / num_classes`를 사용.\n",
    "  - axis: 기본값은 -1. 엔트로피가 계산되는 차원.\n",
    "\n",
    "- 반환:\n",
    "  - 범주형 교차 엔트로피 값."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\n",
    "    \"keras.metrics.categorical_crossentropy\",\n",
    "    \"keras.losses.categorical_crossentropy\",\n",
    ")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def categorical_crossentropy(\n",
    "    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1\n",
    "):\n",
    "    if isinstance(axis, bool):\n",
    "        raise ValueError(\n",
    "            f\"`axis` must be of type `int`. \"\n",
    "            f\"Received: axis={axis} of type {type(axis)}\"\n",
    "        )\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n",
    "\n",
    "    def _smooth_labels():\n",
    "        num_classes = tf.cast(tf.shape(y_true)[-1], y_pred.dtype)\n",
    "        return y_true * (1.0 - label_smoothing) + (\n",
    "            label_smoothing / num_classes\n",
    "        )\n",
    "\n",
    "    y_true = tf.__internal__.smart_cond.smart_cond(\n",
    "        label_smoothing, _smooth_labels, lambda: y_true\n",
    "    )\n",
    "\n",
    "    return backend.categorical_crossentropy(\n",
    "        y_true, y_pred, from_logits=from_logits, axis=axis\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**표준 사용법:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.CategoricalCrossentropy??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 `tf.keras.metrics.CategoricalCrossentropy`\n",
    "- 레이블과 예측 사이의 교차 엔트로피 측정항목을 계산\n",
    "- 이것은 (2 이상) 다중 레이블에 사용되는 교차 엔트로피 측정항목 클래스이다. 여기세서 레이블은 `원-핫` 표현으로 주어진다고 가정한다. 가령, 레이블 값이 [2, 0, 1] 이면, `y_true` = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].\n",
    "\n",
    "**`compile()` API에서 사용:**\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "  optimizer='sgd',\n",
    "  loss='mse',\n",
    "  metrics=[tf.keras.metrics.CategoricalCrossentropy()])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.metrics.CategoricalCrossentropy(\n",
    "    name='categorical_crossentropy',\n",
    "    dtype=None,\n",
    "    from_logits=False,\n",
    "    label_smoothing=0,\n",
    "    axis=-1,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `name`: (선택사양) 측정항목 인스턴스의 문자열 이름.\n",
    "  - `dtype`: (선택사양) 측정항목 결과의 데이터 유형.\n",
    "  - `from_logits`: (선택사양) 출력의 로직 텐서 여부. 기본적으로, 출력은 확률 분포를 인코딩한다고 가정한다.\n",
    "  - `label_smoothing`: (선택사양) [0, 1] 범위의 부동소수점.  \n",
    "     0 보다 크면, 레이블 값은 스므딩되고, 레이블 값에 대한 신뢰도가 완화된다. \n",
    "     가령, `label_smoothing=0.2`는 레이블 `0`에 `0.1` 값을 사용하고 `1` 레이블에 `0.9` 값을 사용함을 의미한다.\n",
    "  - `axis`: (선택사양) 기본값은 -1. 엔트로피가 계산되는 차원."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.metrics.CategoricalCrossentropy\")\n",
    "class CategoricalCrossentropy(base_metric.MeanMetricWrapper):\n",
    "    @dtensor_utils.inject_mesh\n",
    "    def __init__(\n",
    "        self,\n",
    "        name=\"categorical_crossentropy\",\n",
    "        dtype=None,\n",
    "        from_logits=False,\n",
    "        label_smoothing=0,\n",
    "        axis=-1,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            categorical_crossentropy,\n",
    "            name,\n",
    "            dtype=dtype,\n",
    "            from_logits=from_logits,\n",
    "            label_smoothing=label_smoothing,\n",
    "            axis=axis,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPSILON = 1e-7, y = y_true, y` = y_pred\n",
    "# y` = clip_ops.clip_by_value(output, EPSILON, 1. - EPSILON)\n",
    "# y` = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n",
    "# xent = -sum(y * log(y'), axis = -1)\n",
    "#      = -((log 0.95), (log 0.1))\n",
    "#      = [0.051, 2.302]\n",
    "# Reduced xent = (0.051 + 2.302) / 2\n",
    "m = tf.keras.metrics.CategoricalCrossentropy()\n",
    "m.update_state([[0, 1, 0], [0, 0, 1]], \n",
    "               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_state()\n",
    "m.update_state([[0, 1, 0], [0, 0, 1]],\n",
    "               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]],\n",
    "               sample_weight=tf.constant([0.3, 0.7]))\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 `tf.keras.losses.CategoricalCrossentropy`\n",
    "- 레이블과 예측 사이의 교차 엔트로피 측정항목을 계산\n",
    "- 이것은 두 개이상의 다중 레이블에 사용되는 교차 엔트로피 측정항목 클래스이다. 여기세서 레이블은 `원-핫` 표현으로 주어진다고 가정한다. 정수로 레이블이 제공된다면, `SparseCategoricalCrossentropy` 손실을 사용하라. 특성당 `# 클래스` 부동소수점 있어야 한다.\n",
    "- 아래 단편적인 내용에서, 예제당 `# 클래스` 부동 소수점 값이 있다.\n",
    "\n",
    "**`compile()` API에서 사용:**\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    "    reduction='auto',\n",
    "    name='categorical_crossentropy',\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `from_logits`: `y_pred`의 로짓 텐서 여부. \n",
    "    기본적으로, `y_pred`가 확률 분포를 인코딩한다고 가정.\n",
    "  - `label_smoothing`: [0, 1] 범위의 부동소수점. \n",
    "    0 보다 크면, 레이블 값은 스므딩되고, 레이블 값의 신뢰도는 완화됨을 의미한다.\n",
    "    예를 들면, `0.1`이면, 목표 레이블에 대하여 `0.1 / num_classes`에 목표 레이블에 대하여 `0.9 + 0.1 / num_classes`을 사용하라.\n",
    "  - `axis`: 교차 엔트로피를 계산하기 위한 축 (특성 축). 기본값은 -1.\n",
    "  - `reduction`: 손실에 적용할 `tf.keras.losses.Reduction`의 유형. 기본값은 `AUTO`.\n",
    "    `AUTO` indicates that the reduction option will be determined by the usage context. \n",
    "    대부분이 경우 이것의 기본값은 `SUM_OVER_BATCH_SIZE`이다.\n",
    "    `tf.distribute.Strategy`이 사용되면, `tf.keras` `compile` 및 `fit`와 같은 내장 훈련 루프 밖에서 `AUTO` 및 `SUM_OVER_BATCH_SIZE` 사용하면 오류가 발생될 것이다. 자세한 사항은 사용자 훈련 [자습서](https://www.tensorflow.org/tutorials/distribute/custom_training) 참조하라.\n",
    "  - `name`: 인스턴스의 선택사양 이름. 기본값은 'categorical_crossentropy'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.losses.CategoricalCrossentropy\")\n",
    "class CategoricalCrossentropy(LossFunctionWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        from_logits=False,\n",
    "        label_smoothing=0.0,\n",
    "        axis=-1,\n",
    "        reduction=losses_utils.ReductionV2.AUTO,\n",
    "        name=\"categorical_crossentropy\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            categorical_crossentropy,\n",
    "            name=name,\n",
    "            reduction=reduction,\n",
    "            from_logits=from_logits,\n",
    "            label_smoothing=label_smoothing,\n",
    "            axis=axis,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling with 'sample_weight'.\n",
    "cce(y_true, y_pred, sample_weight=tf.constant([0.3, 0.7])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'sum' reduction type.\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using 'none' reduction type.\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 희소 범주형 교차 엔트로피\n",
    "- 희소 범주형 교차 엔트로피 손실을 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 tf.keras.backend.sparse_categorical_crossentropy\n",
    "- 정수 목표를 갖는 범주형 교차 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.backend.sparse_categorical_crossentropy(\n",
    "    target,\n",
    "    output,\n",
    "    from_logits=False,\n",
    "    axis=-1,\n",
    "    ignore_class=None,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "    - `target`: 정수 텐서.\n",
    "    - `output`: 소프트맥스의 텐서 결과 (`from_logits`가 참이 아니면, 이 경우 `output`은 로짓이 될 것으로 예상)\n",
    "    - `from_logits`: 참/거짓, `output`이 소프트맥스의 결과 또는 로짓의 텐서인지 여부\n",
    "    - `axis`: 채널 축을 지정하는 정수. `axis=-1`은 데이터 포맷 `channels_last`이고, `axis=1`은 `channels_first`에 상응\n",
    "    - `ignore_class`: 선택적으로 정수. 손실 계산중에 ID는 무시된다.\n",
    "       이것은 유용한데, 예를 들어, 분할 맵에서 \"void\" 클래스(일반적으로 -1 또는 255)를 특성으로 하는 분할 문제에 유용하다.\n",
    "       기본적으로 (`ignore_class=None`), 모든 클래스는 고려된다.\n",
    "\n",
    "- Returns:\n",
    "    - 츨략 텐서.\n",
    "\n",
    "- Raises:\n",
    "    - `ValueError`: if `axis`가 -1 아니거나 `output`의 축 중 하나가 아닐 경우."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.backend.sparse_categorical_crossentropy\")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "@doc_controls.do_not_generate_docs\n",
    "def sparse_categorical_crossentropy(\n",
    "    target, output, from_logits=False, axis=-1, ignore_class=None\n",
    "):\n",
    "    target = tf.convert_to_tensor(target)\n",
    "    output = tf.convert_to_tensor(output)\n",
    "\n",
    "    target = cast(target, \"int64\")\n",
    "\n",
    "    output, from_logits = _get_logits(\n",
    "        output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n",
    "    )\n",
    "    if not from_logits:\n",
    "        epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n",
    "        output = tf.clip_by_value(output, epsilon_, 1 - epsilon_)\n",
    "        output = tf.math.log(output)\n",
    "\n",
    "    # Permute output so that the last axis contains the logits/probabilities.\n",
    "    if isinstance(output.shape, (tuple, list)):\n",
    "        output_rank = len(output.shape)\n",
    "    else:\n",
    "        output_rank = output.shape.ndims\n",
    "    if output_rank is not None:\n",
    "        axis %= output_rank\n",
    "        if axis != output_rank - 1:\n",
    "            permutation = list(\n",
    "                itertools.chain(\n",
    "                    range(axis), range(axis + 1, output_rank), [axis]\n",
    "                )\n",
    "            )\n",
    "            output = tf.compat.v1.transpose(output, perm=permutation)\n",
    "    elif axis != -1:\n",
    "        raise ValueError(\n",
    "            \"Cannot compute sparse categorical crossentropy with `axis={}` \"\n",
    "            \"on an output tensor with unknown rank\".format(axis)\n",
    "        )\n",
    "\n",
    "    # Try to adjust the shape so that rank of labels = rank of logits - 1.\n",
    "    output_shape = tf.shape(output)\n",
    "    target_rank = target.shape.ndims\n",
    "\n",
    "    update_shape = (\n",
    "        target_rank is not None\n",
    "        and output_rank is not None\n",
    "        and target_rank != output_rank - 1\n",
    "    )\n",
    "    if update_shape:\n",
    "        target = flatten(target)\n",
    "        output = tf.reshape(output, [-1, output_shape[-1]])\n",
    "\n",
    "    if ignore_class is not None:\n",
    "        valid_mask = tf.not_equal(target, cast(ignore_class, target.dtype))\n",
    "        target = target[valid_mask]\n",
    "        output = output[valid_mask]\n",
    "\n",
    "    if py_any(_is_symbolic_tensor(v) for v in [target, output]):\n",
    "        with get_graph().as_default():\n",
    "            res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels=target, logits=output\n",
    "            )\n",
    "    else:\n",
    "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=target, logits=output\n",
    "        )\n",
    "\n",
    "    if ignore_class is not None:\n",
    "        res_shape = cast(output_shape[:-1], \"int64\")\n",
    "        valid_mask = tf.reshape(valid_mask, res_shape)\n",
    "        res = tf.scatter_nd(tf.where(valid_mask), res, res_shape)\n",
    "        res._keras_mask = valid_mask\n",
    "\n",
    "        return res\n",
    "\n",
    "    if update_shape and output_rank >= 3:\n",
    "        # If our output includes timesteps or\n",
    "        # spatial dimensions we need to reshape\n",
    "        res = tf.reshape(res, output_shape[:-1])\n",
    "\n",
    "    return res\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 `tf.keras.[metrics|losses].sparse_categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.metrics.sparse_categorical_crossentropy(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    from_logits=False,\n",
    "    axis=-1,\n",
    "    ignore_class=None,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `y_true`: 실측값.\n",
    "  - `y_pred`: 예측값.\n",
    "  - `from_logits`: `y_pred`의 로짓 텐서 여부. 기본적으로, `y_pred`가 확률 분포를 인코딩한다고 가정.\n",
    "  - `axis`: 기본값은 -1. 엔트로피가 계산되는 축.\n",
    "  - `ignore_class`: 선택적으로 정수. 손실 계산중에 ID는 무시된다.\n",
    "     이것은 유용한데, 예를 들어, 분할 맵에서 \"void\" 클래스(일반적으로 -1 또는 255)를 특성으로 하는 분할 문제에 유용하다.\n",
    "     기본적으로 (`ignore_class=None`), 모든 클래스는 고려된다.\n",
    "\n",
    "- 반환:\n",
    "  - 희소 범주형 교차 엔트로피 손실 값.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\n",
    "    \"keras.metrics.sparse_categorical_crossentropy\",\n",
    "    \"keras.losses.sparse_categorical_crossentropy\",\n",
    ")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def sparse_categorical_crossentropy(\n",
    "    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None\n",
    "):\n",
    "    return backend.sparse_categorical_crossentropy(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        from_logits=from_logits,\n",
    "        ignore_class=ignore_class,\n",
    "        axis=axis,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = [1, 2]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[[ 0,  2],\n",
    "           [-1, -1]],\n",
    "          [[ 0,  2],\n",
    "           [-1, -1]]]\n",
    "y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
    "           [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
    "          [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
    "           [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, ignore_class=-1)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 `tf.keras.metrics.SparseCategoricalCrossentropy`\n",
    "\n",
    "- 두 개 이상의 레이블 클래스가 있는 경우 이 교차 엔트로피 측정항목을 사용하라.\n",
    "  레이블은 정수로 제공될 것으로 예상된다. `원-핫` 표현을 사용하여 레이블을 제공하려면 `CategoricalCrossentropy` 측정항목을 사용하라.\n",
    "  `y_pred`에 대해 특성당 `# 클래스` 부동소수점 값이 있어야 하고 `y_true`에 대해 특성당 단일 부동소수점 값이 있어야 한다.\n",
    "\n",
    "- 아래 단편적인 내용에서, `y_true`에 대한 예제당 단일 부동 소수점 값과 `y_pred`에 대한 예제당 `# 클래스` 부동 소수점 값이 있다.\n",
    "  `y_true`의 형태는 `[batch_size]` 이고 `y_pred`의 형태는 `[batch_size, num_classes]`.\n",
    "\n",
    "\n",
    "- `compile()` API에서:\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "  optimizer='sgd',\n",
    "  loss='mse',\n",
    "  metrics=[tf.keras.metrics.SparseCategoricalCrossentropy()])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.metrics.SparseCategoricalCrossentropy(\n",
    "    name: str = 'sparse_categorical_crossentropy',\n",
    "    dtype: Union[str, tensorflow.python.framework.dtypes.DType, NoneType] = None,\n",
    "    from_logits: bool = False,\n",
    "    ignore_class: Optional[int] = None,\n",
    "    axis: int = -1,\n",
    ")\n",
    "```\n",
    "\n",
    "- Args:\n",
    "  - name: (선택적) 측정항목 인스턴스 문자열 이름.\n",
    "  - dtype: (선택적) 측정항목 결과의 데이터 유형.\n",
    "  - from_logits: (선택적)y_pred`가 로짓 텐서로 예상되는지 여부. 기본적으로, `y_pred`가 확률 분포를 인코드한다고 가정.\n",
    "  - ignore_class: 선택적으로 정수. 손실 계산중에 ID는 무시된다.\n",
    "     이것은 유용한데, 예를 들어, 분할 맵에서 \"void\" 클래스(일반적으로 -1 또는 255)를 특성으로 하는 분할 문제에 유용하다.\n",
    "     기본적으로 (`ignore_class=None`), 모든 클래스는 고려된다.\n",
    "  - axis: (선택적) 기본값은 -1. 엔트로피가 계산되는 차원."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.metrics.SparseCategoricalCrossentropy\")\n",
    "class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n",
    "    @dtensor_utils.inject_mesh\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str = \"sparse_categorical_crossentropy\",\n",
    "        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n",
    "        from_logits: bool = False,\n",
    "        ignore_class: Optional[int] = None,\n",
    "        axis: int = -1,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            sparse_categorical_crossentropy,\n",
    "            name,\n",
    "            dtype=dtype,\n",
    "            from_logits=from_logits,\n",
    "            ignore_class=ignore_class,\n",
    "            axis=axis,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]\n",
    "# logits = log(y_pred)\n",
    "# softmax = exp(logits) / sum(exp(logits), axis=-1)\n",
    "# softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]\n",
    "# xent = -sum(y * log(softmax), 1)\n",
    "# log(softmax) = [[-2.9957, -0.0513, -16.1181],\n",
    "#                 [-2.3026, -0.2231, -2.3026]]\n",
    "# y_true * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]\n",
    "# xent = [0.0513, 2.3026]\n",
    "# Reduced xent = (0.0513 + 2.3026) / 2\n",
    "m = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "m.update_state([1, 2],\n",
    "               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_state()\n",
    "m.update_state([1, 2],\n",
    "               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]],\n",
    "               sample_weight=tf.constant([0.3, 0.7]))\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.losses.SparseCategoricalCrossentropy??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 `tf.keras.losses.SparseCategoricalCrossentropy`\n",
    "\n",
    "- 두 개 이상의 레이블 클래스가 있는 경우 이 교차 엔트로피 측정항목을 사용하라.\n",
    "  레이블은 정수로 제공될 것으로 예상된다. `원-핫` 표현을 사용하여 레이블을 제공하려면 `CategoricalCrossentropy` 측정항목을 사용하라.\n",
    "  `y_pred`에 대해 특성당 `# 클래스` 부동소수점 값이 있어야 하고 `y_true`에 대해 특성당 단일 부동소수점 값이 있어야 한다.\n",
    "\n",
    "- 아래 단편적인 내용에서, `y_true`에 대한 예제당 단일 부동 소수점 값과 `y_pred`에 대한 예제당 `# 클래스` 부동 소수점 값이 있다.\n",
    "  `y_true`의 형태는 `[batch_size]` 이고 `y_pred`의 형태는 `[batch_size, num_classes]`.\n",
    "\n",
    "\n",
    "- `compile()` API에서:\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    ignore_class=None,\n",
    "    reduction='auto',\n",
    "    name='sparse_categorical_crossentropy',\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `from_logits`: `y_pred`가 로짓 텐서로 예상되는지 여부. 기본적으로, `y_pred`가 확률 분포를 인코드한다고 가정.\n",
    "  - `ignore_class`: 선택적으로 정수. 손실 계산중에 ID는 무시된다.\n",
    "     이것은 유용한데, 예를 들어, 분할 맵에서 \"void\" 클래스(일반적으로 -1 또는 255)를 특성으로 하는 분할 문제에 유용하다.\n",
    "     기본적으로 (`ignore_class=None`), 모든 클래스는 고려된다.\n",
    "  - `reduction`: 손실에 적용할 `tf.keras.losses.Reduction`의 유형. 기본값은 `AUTO`.\n",
    "    `AUTO` indicates that the reduction option will be determined by the usage context. \n",
    "    대부분이 경우 이것의 기본값은 `SUM_OVER_BATCH_SIZE`이다.\n",
    "    `tf.distribute.Strategy`이 사용되면, `tf.keras` `compile` 및 `fit`와 같은 내장 훈련 루프 밖에서 `AUTO` 및 `SUM_OVER_BATCH_SIZE` 사용하면 오류가 발생될 것이다. 자세한 사항은 사용자 훈련 [자습서](https://www.tensorflow.org/tutorials/distribute/custom_training) 참조하라.\n",
    "  - `name`: 인스턴스에 대한 선택적 이름. 기본값은 'sparse_categorical_crossentropy'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.losses.SparseCategoricalCrossentropy\")\n",
    "class SparseCategoricalCrossentropy(LossFunctionWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        from_logits=False,\n",
    "        ignore_class=None,\n",
    "        reduction=losses_utils.ReductionV2.AUTO,\n",
    "        name=\"sparse_categorical_crossentropy\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            sparse_categorical_crossentropy,\n",
    "            name=name,\n",
    "            reduction=reduction,\n",
    "            from_logits=from_logits,\n",
    "            ignore_class=ignore_class,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 2]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "scce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling with 'sample_weight'.\n",
    "scce(y_true, y_pred, sample_weight=tf.constant([0.3, 0.7])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'sum' reduction type.\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=tf.keras.losses.Reduction.SUM)\n",
    "scce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'none' reduction type.\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    reduction=tf.keras.losses.Reduction.NONE)\n",
    "scce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 이진 교차 엔트로피 (backend)\n",
    "- 출력 텐서와 목표 텐서 사이의 이진 교차 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "    \n",
    "```python\n",
    "tf.keras.backend.binary_crossentropy(target, output, from_logits=False)\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "    - `target`: `output`과 동일 형태를 가지는 텐서.\n",
    "    - `output`: 텐서.\n",
    "    - `from_logits`: `output`이 로짓 텐서인지 여부. 기본적으로, `output`이 확률 분포를 인코딩한다고 가정.\n",
    "\n",
    "- 반환:\n",
    "    - 텐서."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.backend.binary_crossentropy\")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def binary_crossentropy(target, output, from_logits=False):\n",
    "    target = tf.convert_to_tensor(target)\n",
    "    output = tf.convert_to_tensor(output)\n",
    "\n",
    "    output, from_logits = _get_logits(\n",
    "        output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n",
    "    )\n",
    "    if from_logits:\n",
    "        return tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=target, logits=output\n",
    "        )\n",
    "\n",
    "    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n",
    "\n",
    "    # 확률로 부터 교차 엔트로피 계산.\n",
    "    bce = target * tf.math.log(output + epsilon())\n",
    "    bce += (1 - target) * tf.math.log(1 - output + epsilon())\n",
    "    return -bce\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 이진 교차 엔트로피 (metrics & losses)\n",
    "- 이진 교차 엔트로피 손실 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 `tf.keras.[metrics|losses].binary_crossentropy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "binary_crossentropy(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `y_true`: 실측값. 형태 = `[batch_size, d0, .. dN]`.\n",
    "  - `y_pred`: 예측값. 형태 = `[batch_size, d0, .. dN]`.\n",
    "  - `from_logits`: `y_pred`가 로짓 텐서인지 여부. 기본적으로, `y_pred`가 확률 분포를 인코딩한다고 가정.\n",
    "  - `label_smoothing`: [0, 1] 범위의 부동소수점. `0`보다 크면 레이블을 0.5 방향으로 압축하여 레이블을 부드럽게 한다.\n",
    "    즉, 대상 클래스에 대하여 `1. - 0.5 * label_smoothing`, 비대상 클래스에 대하여 `0.5 * label_smoothing`.\n",
    "  - `axis`: 평균이 계산되는 축. 기본값은 -1.\n",
    "\n",
    "- 반환:\n",
    "  - 이진 교차 엔트로피 손실 값. 형태 = `[batch_size, d0, .. dN-1]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "\n",
    "@keras_export(\n",
    "    \"keras.metrics.binary_crossentropy\", \"keras.losses.binary_crossentropy\"\n",
    ")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def binary_crossentropy(\n",
    "    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1\n",
    "):\n",
    "\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n",
    "\n",
    "    def _smooth_labels():\n",
    "        return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
    "\n",
    "    y_true = tf.__internal__.smart_cond.smart_cond(\n",
    "        label_smoothing, _smooth_labels, lambda: y_true\n",
    "    )\n",
    "\n",
    "    return backend.mean(\n",
    "        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n",
    "        axis=axis,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**표준 사용법:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = [[0, 1], [0, 0]]\n",
    "y_pred = [[0.6, 0.4], [0.4, 0.6]]\n",
    "loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 `tf.keras.metrics.BinaryCrossentropy`\n",
    "- 레이블과 예측 사이의 교차 엔트로피 행렬을 계산\n",
    "- 이것은 오직 (0과 1) 두 레이블 클래스만 있는 경우에 사용되는 교차 엔트로피 측정항목 클래스이다.\n",
    "\n",
    "**`compile()` API 에서 사용:**\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='mse',\n",
    "    metrics=[tf.keras.metrics.BinaryCrossentropy()])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.metrics.BinaryCrossentropy(\n",
    "    name='binary_crossentropy',\n",
    "    dtype=None,\n",
    "    from_logits=False,\n",
    "    label_smoothing=0,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `name`: (선택사양) 측정항목 인스턴스의 문자열 이름.\n",
    "  - `dtype`: (선택사양) 측정항목 결과의 데이터 유형.\n",
    "  - `from_logits`: (선택사양) 출력이 로직 텐서 여부.\n",
    "    기본적으로, 출력은 확률 분포를 인코딩한다고 간주.\n",
    "  - `label_smoothing`: (선택사양) 범위의 부동소수점.\n",
    "    0 보다 크면, 레이블 값은 부드러워지고, 레이블 값에 대한 신뢰도가 완화됨을 의미한다.\n",
    "    예를 들면, `label_smoothing=0.2`은 레이블 `0`에 대하여 `0.1`을, 레이블 `1`에 대하여 `0.9`을 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.metrics.BinaryCrossentropy\")\n",
    "class BinaryCrossentropy(base_metric.MeanMetricWrapper):\n",
    "    @dtensor_utils.inject_mesh\n",
    "    def __init__(\n",
    "        self,\n",
    "        name=\"binary_crossentropy\",\n",
    "        dtype=None,\n",
    "        from_logits=False,\n",
    "        label_smoothing=0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            binary_crossentropy,\n",
    "            name,\n",
    "            dtype=dtype,\n",
    "            from_logits=from_logits,\n",
    "            label_smoothing=label_smoothing,\n",
    "        )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.BinaryCrossentropy()\n",
    "m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_state()\n",
    "m.update_state([[0, 1], [0, 0]], [[0.6, 0.4], [0.4, 0.6]], sample_weight=[1, 0])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 `tf.keras.losses.BinaryCrossentropy`\n",
    "- 레이블과 예측 사이의 교차 엔트로피 행렬을 계산\n",
    "- 이진 (0 또는 1) 분류 애플리케이션에 대하여 이 교차-엔트로피 손실을 사용하라.\n",
    "- 손실 함수는 다음 입력을 요구한다:\n",
    "    - `y_true` (실측 값): 이것은 0 또는 1.\n",
    "    - `y_pred` (예측 값): 이것은 모델의 예측, 가령, [로짓](https://en.wikipedia.org/wiki/Logit) 또는 확률을 나타내는 단일 부동소수점 값.\n",
    "       (`from_logits=True`이면 [-inf, inf] 범위의 값, `from_logits=False`이면 [0., 1.]의 값)\n",
    "       \n",
    "      **권장 사용법:** (`from_logits=True` 설정)\n",
    "\n",
    "**`tf.keras` API 에서:**\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "  ....\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    "    reduction='auto',\n",
    "    name='binary_crossentropy',\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `from_logits`: `y_pred`를 [로짓](https://en.wikipedia.org/wiki/Logit) 값으로 해석할지 여부.\n",
    "    기본적으로, `y_pred`이 확률을 담고 있다고 가정 (가령, [0, 1] 범위 값). \n",
    "  - `label_smoothing`: [0, 1] 범위의 부동소수점. 0 이면, 스무딩이 발생하지 않는다. \n",
    "    0 보다 크면, 예측 레이블과 실제 레이블의 스무딩 버전 사이의 손실을 계산한다. 여기서 스무딩은 레이블을 0.5로 압축한다.\n",
    "    `label_smoothing`의 값이 클수록 스무딩이 심해진다.\n",
    "  - `axis`: 교차 엔트로피를 계산할 축(특성 축). 기본값은 -1.\n",
    "  - `reduction`: 손실에 적용할 `tf.keras.losses.Reduction`의 유형. 기본값은 `AUTO`.\n",
    "     `AUTO`는 축소 옵션이 사용 컨텍스트에 따라 결정됨을 나타낸다. 대부분의 경우, 기본값은 `SUM_OVER_BATCH_SIZE`이다. \n",
    "     `tf.distribute.Strategy`와 함께 사용하는 경우, `tf.keras` `compile` 및 `fit`과 같은 내장 훈련 루프 외부에서 `AUTO` 또는 `SUM_OVER_BATCH_SIZE`를 사용하면 오류가 발생한다.\n",
    "     상세한 사항은 이 사용자 훈련 [자습서](https://www.tensorflow.org/tutorials/distribute/custom_training) 참조하라.\n",
    "  - `name`: 연산에 대한 이름. 기본 값은 'binary_crossentropy'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.losses.BinaryCrossentropy\")\n",
    "class BinaryCrossentropy(LossFunctionWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        from_logits=False,\n",
    "        label_smoothing=0.0,\n",
    "        axis=-1,\n",
    "        reduction=losses_utils.ReductionV2.AUTO,\n",
    "        name=\"binary_crossentropy\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            binary_crossentropy,\n",
    "            name=name,\n",
    "            reduction=reduction,\n",
    "            from_logits=from_logits,\n",
    "            label_smoothing=label_smoothing,\n",
    "            axis=axis,\n",
    "        )\n",
    "        self.from_logits = from_logits\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: (batch_size = 1, number of samples = 4)\n",
    "y_true = [0, 1, 0, 0]\n",
    "y_pred = [-18.6, 0.51, 2.94, -12.8]\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "bce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: (batch_size = 2, number of samples = 4)\n",
    "y_true = [[0, 1], [0, 0]]\n",
    "y_pred = [[-18.6, 0.51], [2.94, -12.8]]\n",
    "# Using default 'auto'/'sum_over_batch_size' reduction type.\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "bce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'sample_weight' attribute\n",
    "bce(y_true, y_pred, sample_weight=[0.8, 0.2]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'sum' reduction` type.\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "bce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'none' reduction type.\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "bce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기본 사용법:** (`from_logits=False` 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the following updates to the above \"Recommended Usage\" section\n",
    "# 1. Set `from_logits=False`\n",
    "tf.keras.losses.BinaryCrossentropy() # OR ...('from_logits=False')\n",
    "# 2. Update `y_pred` to use probabilities instead of logits\n",
    "y_pred = [0.6, 0.3, 0.2, 0.8] # OR [[0.6, 0.3], [0.2, 0.8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 평균 제곱 오차\n",
    "- Mean Squared Error, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 `tf.keras.[metrics|losses].mse`\n",
    "- 레이블과 예측 사이의 평균 제곱 오차를 계산\n",
    "- 입력 사이의 제곱 거리를 계산한 후, 마지막 차원의 평균 값이 반환\n",
    "- `loss = mean(square(y_true - y_pred), axis=-1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.metrics.mse(y_true, y_pred)\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `y_true`: 실측값. 형태 = `[batch_size, d0, .. dN]`.\n",
    "  - `y_pred`: 예측값. 형태 = `[batch_size, d0, .. dN]`.\n",
    "\n",
    "- 반환:\n",
    "  - 평균 제곱 오차 값. 형태 = `[batch_size, d0, .. dN-1]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:*\n",
    "\n",
    "```python\n",
    "@keras_export(\n",
    "    \"keras.metrics.mean_squared_error\",\n",
    "    \"keras.metrics.mse\",\n",
    "    \"keras.metrics.MSE\",\n",
    "    \"keras.losses.mean_squared_error\",\n",
    "    \"keras.losses.mse\",\n",
    "    \"keras.losses.MSE\",\n",
    ")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.randint(0, 2, size=(2, 3))\n",
    "y_pred = np.random.random(size=(2, 3))\n",
    "loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "assert np.array_equal(loss.numpy(), np.mean(np.square(y_true - y_pred), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 평균 절대 오차\n",
    "- Mean Absolute Error, MAE\n",
    "- 레이블과 예측 사이의 평균 절대 오차를 계산\n",
    "- `loss = mean(abs(y_true - y_pred), axis=-1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 `tf.keras.[metrics|losses].mae`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.losses.mae(y_true, y_pred)\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `y_true`: 실측값. 형태 = `[batch_size, d0, .. dN]`.\n",
    "  - `y_pred`: 예측값. 형태 = `[batch_size, d0, .. dN]`.\n",
    "\n",
    "- 반환:\n",
    "  - 평균 제곱 오차 값. 형태 = `[batch_size, d0, .. dN-1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\n",
    "    \"keras.metrics.mean_absolute_error\",\n",
    "    \"keras.metrics.mae\",\n",
    "    \"keras.metrics.MAE\",\n",
    "    \"keras.losses.mean_absolute_error\",\n",
    "    \"keras.losses.mae\",\n",
    "    \"keras.losses.MAE\",\n",
    ")\n",
    "@tf.__internal__.dispatch.add_dispatch_support\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    return backend.mean(tf.abs(y_pred - y_true), axis=-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.random.randint(0, 2, size=(2, 3))\n",
    "y_pred = np.random.random(size=(2, 3))\n",
    "loss = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "assert np.array_equal(loss.numpy(), np.mean(np.abs(y_true - y_pred), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 평균 제곱근 전파\n",
    "- Root Mean Square Propagation, RMSprop\n",
    "- RMSprop 요점은 다음과 같다:\n",
    "  - 경사 제곱의 이동 평균 유지한다.\n",
    "  - 경사를 이 평균의 근으로 나눈다.\n",
    "- 참고: [Hinton, 2012](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 `tf.keras.optimizers.RMSprop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-07,\n",
    "    centered=False,\n",
    "    name='RMSprop',\n",
    "    **kwargs,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `learning_rate`: `Tensor`, 부동소수점 값, 또는 \n",
    "    `tf.keras.optimizers.schedules.LearningRateSchedule`로 예정된 것, \n",
    "    또는 인자를 받지 않고 사용할 실제 값을 반환하는 호출가능. 학습 비율. 기본값은 0,001.\n",
    "  - `rho`: 히스토리/도래되는 경사에 대한 할인 요소. 기본값은 0.9.\n",
    "  - `momentum`: 스칼라 또는 스칼라 `Tensor`. 기본값은 0.0.\n",
    "  - `epsilon`: 수치 안정성을 위한 작은 상수. \n",
    "    이 엡실론은 알고리즘 1의 엡실론이 아니라 Kingma 과 Ba 논문(섹션 2.1 직전 공식)의 \"엡실론 햇\"이다. 기본값은 1e-7.\n",
    "  - `centered`: 참/거짓. If `True`, 경사는 경사의 예측된 변수에 의해 정규화된다; 거짓이면, 집중되지 않은 두 번째 순간에 의해.\n",
    "    이것을 'True'로 설정하면 학습에 도움이 될 수 있지만 계산 및 메모리 측면에서 약간 더 비싸다. 기본값은 `False`.\n",
    "  - `name`: 경사를 적용할 때 생성되는 연사에 대한 선택적 이름 접두사. 기본값은 `\"RMSprop\"`.\n",
    "  - `**kwargs`: 키워드 인자. keyword arguments. 허용되는 인자는 `clipvalue`, `clipnorm`, `global_clipnorm` 이다.\n",
    "    `clipvalue` (부동소수점) 설정되면, 각 가중치의 경사는 이 값보다 높지 않도록 잘린다.\n",
    "    `clipnorm` (부동소수점) 설정되면, 각 가중치의 경사는 개별적으로 잘려서 정규값이이 이 값보다 높지 않다.\n",
    "    `global_clipnorm` (부동소수점) 설정되면, 전역 정규값이 이 값보다 높지 않도록 모든 가중치의 경사가 잘린다.\n",
    "\n",
    "\n",
    "- 이 RMSprop 구현은 Nesterov 모멘텀이 아닌 일반 모멘텀을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**사용법:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2) / 2.0    # d(loss) / d(var1) = var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 정확도 (측정항목)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 `tf.keras.metrics.Accuracy`\n",
    "\n",
    "- 예측이 레이블과 동일한 빈도를 계산\n",
    "\n",
    "- 이 측정항목은 `y_pred`가 `y_true`와 일치하는 빈도를 계산하는 데 사용되는 `total` 및 `count`라는 두 개의 로컬 변수를 생성한다.\n",
    "  이 빈도는 궁극적으로 `binary accuracy` 반환한다: 단순히 `total`을 `count`로 나누는 멱등성 연산이다.\n",
    "\n",
    "- `sample_weight`가 `None`이면, 가중치 기본값은 1이다. 0의 `sample_weight`를 사용하여 값을 마스크한다.\n",
    "\n",
    "\n",
    "\n",
    "- Usage with `compile()` API:\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.Accuracy()])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.metrics.Accuracy(name='accuracy', dtype=None)\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `name`: (선택적) 측정 항목 인스턴스의 문자열 이름.\n",
    "  - `dtype`: (선택적) 측정 항목의 데이터 유형."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.metrics.Accuracy\")\n",
    "class Accuracy(base_metric.MeanMetricWrapper):\n",
    "    @dtensor_utils.inject_mesh\n",
    "    def __init__(self, name=\"accuracy\", dtype=None):\n",
    "        super().__init__(accuracy, name, dtype=dtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.Accuracy()\n",
    "m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [4]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_state()\n",
    "m.update_state([[1], [2], [3], [4]], [[0], [2], [3], [4]], sample_weight=[1, 1, 0, 0])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 ` tf.keras.metrics.BinaryAccuracy`\n",
    "\n",
    "- 이진 레이블에 일치하는 예측 빈도 계산.\n",
    "\n",
    "- 이 측정항목은 `y_pred`가 `y_true`와 일치하는 빈도를 계산하는 데 사용되는 `total` 및 `count`라는 두 개의 로컬 변수를 생성한다.\n",
    "  이 빈도는 궁극적으로 `binary accuracy` 반환한다: 단순히 `total`을 `count`로 나누는 멱등성 연산이다.\n",
    "\n",
    "- `sample_weight`가 `None`이면, 가중치 기본값은 1이다. 0의 `sample_weight`를 사용하여 값을 마스크한다.\n",
    "\n",
    "    \n",
    "- `compile()` API 사용례:\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**서명:**\n",
    "\n",
    "```python\n",
    "tf.keras.metrics.BinaryAccuracy(\n",
    "    name='binary_accuracy',\n",
    "    dtype=None,\n",
    "    threshold=0.5,\n",
    ")\n",
    "```\n",
    "\n",
    "- 인자:\n",
    "  - `name`: (선택적) 측정 항목 인스턴스의 문자열 이름.\n",
    "  - `dtype`: (선택적) 측정 항목 결과의 데이터 유형.\n",
    "  - `threshold`: (선택적) 예측 값이 1 또는 0인지 결정하기 위한 임계값을 나타내는 부동소수점."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**소스:**\n",
    "\n",
    "```python\n",
    "@keras_export(\"keras.metrics.BinaryAccuracy\")\n",
    "class BinaryAccuracy(base_metric.MeanMetricWrapper):\n",
    "    @dtensor_utils.inject_mesh\n",
    "    def __init__(self, name=\"binary_accuracy\", dtype=None, threshold=0.5):\n",
    "        super().__init__(\n",
    "            metrics_utils.binary_matches, name, dtype=dtype, threshold=threshold\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**독립 실행형 사용:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.BinaryAccuracy()\n",
    "m.update_state([[1], [1], [0], [0]], [[0.98], [1], [0], [0.6]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_state()\n",
    "m.update_state([[1], [1], [0], [0]], [[0.98], [1], [0], [0.6]], sample_weight=[1, 0, 0, 1])\n",
    "m.result().numpy()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter04_getting-started-with-neural-networks.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
